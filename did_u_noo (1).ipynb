{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Covert video to audio"
      ],
      "metadata": {
        "id": "umU6HEXpMpM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmO5drWMssi",
        "outputId": "bfabc523-4338-4fb5-e0ea-f38144c13f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *\n",
        "video = VideoFileClip(\"example.mp4\")\n",
        "# Getting audio from video\n",
        "video.audio.write_audiofile(\"example.mp3\")"
      ],
      "metadata": {
        "id": "utKCjBF5J7-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5d9426-10b9-4294-d47b-a519509c0a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in example.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting Audio to text"
      ],
      "metadata": {
        "id": "LbZ1iG0CUW5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "uSING OPEN ai"
      ],
      "metadata": {
        "id": "qMQV-auraIUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do_hNIjYM-vD",
        "outputId": "26a0b8d6-275c-4289-e715-6d33002c1651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.6.2)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.4\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "FLOXGEruwMVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de71205-38c2-45c3-ead4-2fa0742a9f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m903.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "#from openai import Client\n",
        "\n",
        "#client = openai.api.Client(api_key = 'sk-proj-8uShPZBYy4t9LmzTlYoRT3BlbkFJXY2mTZcNB7gkVlgFe1B6')\n",
        "openai.api_key = 'sk-proj-8uShPZBYy4t9LmzTlYoRT3BlbkFJXY2mTZcNB7gkVlgFe1B6'\n",
        "\n",
        "# Function to transcribe audio using OpenAI API\n",
        "def transcribe_audio(file_path):\n",
        "    with open(file_path, \"rb\") as audio_file:\n",
        "        transcription = openai.Audio.transcribe(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file\n",
        "        )\n",
        "    return transcription.text\n",
        "\n",
        "# Load your MP3 file\n",
        "audio_file_path = \"/content/How Large Language Models Work.mp3\"\n",
        "audio = AudioSegment.from_mp3(audio_file_path)\n",
        "\n",
        "# Break audio into segments\n",
        "segment_length = 26 * 60 * 1000  # 26 minutes in milliseconds\n",
        "segments = [audio[i:i+segment_length] for i in range(0, len(audio), segment_length)]\n",
        "\n",
        "# Directory to save temporary audio segments\n",
        "if not os.path.exists(\"temp_segments\"):\n",
        "    os.makedirs(\"temp_segments\")\n",
        "\n",
        "# Transcribe each segment\n",
        "transcriptions = []\n",
        "for i, segment in enumerate(segments):\n",
        "    segment_path = f\"temp_segments/segment_{i}.mp3\"\n",
        "    segment.export(segment_path, format=\"mp3\")\n",
        "    transcription = transcribe_audio(segment_path)\n",
        "    transcriptions.append(transcription)\n",
        "\n",
        "# Combine transcriptions and save to a file\n",
        "transcription_text = \"\\n\".join(transcriptions)\n",
        "output_filename = \"transcription.txt\"\n",
        "with open(output_filename, \"w\") as f:\n",
        "    f.write(transcription_text)\n",
        "\n",
        "print(f\"Transcription saved to {output_filename}\")\n",
        "\n",
        "# Load the transcribed text from the file\n",
        "with open(output_filename, \"r\") as f:\n",
        "    example_text = f.read()\n",
        "\n",
        "print(example_text)\n"
      ],
      "metadata": {
        "id": "H3dR406F47AL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9d95b2-a949-4089-f5f4-04382722c04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription saved to transcription.txt\n",
            "GPT, or generative pre-trained transformer, is a large language model, or an LLM, that can generate human-like text. And I've been using GPT in its various forms for years. In this video, we are going to, number one, ask what is an LLM? Number two, we are going to describe how they work. And then, number three, we are going to ask what are the business applications of LLMs. So let's start with number one, what is a large language model? Well, a large language model is an instance of something else, called a foundation model. Now foundation models are pre-trained on large amounts of unlabeled and self-supervised data, meaning the model learns from patterns in the data in a way that produces generalizable and adaptable output. And large language models are instances of foundation models applied specifically to text and text-like things. I'm talking about things like code. Now large language models are trained on large datasets of text, such as books, articles, and conversations. And look, when we say large, these models can be tens of gigabytes in size and trained on enormous amounts of text data. We're talking potentially petabytes of data here. So to put that into perspective, a text file that is, let's say, one gigabyte in size, that can store about 178 million words, a lot of words just in one GB. And how many gigabytes are in a petabyte? Well, it's about one million. Yeah, that's truly a lot of text. Now LLMs are also among the biggest models when it comes to parameter count. A parameter is a value the model can change independently as it learns, and the more parameters a model has, the more complex it can be. GTP3, for example, is pre-trained on a corpus of actually 45 terabytes of data. And it uses 175 billion ML parameters. All right, so how do they work? Well, we can think of it like this. LLM equals three things. Data, architecture, and lastly, we can think of it as training. Those three things are really the components of an LLM. Now, we've already discussed the enormous amounts of text data that goes into these things. As for the architecture, this is a neural network, and for GPT, that is a transformer. And the transformer architecture enables the model to handle sequences of data, like sentences or lines of code. And transformers are designed to understand the context of each word in a sentence by considering it in relation to every other word. This allows the model to build a comprehensive understanding of the sentence structure and the meaning of the words within it. And then this architecture is trained on all of this large amount of data. Now, during training, the model learns to predict the next word in a sentence. So the sky is, it starts off with a random guess, the sky is bug. But with each iteration, the model adjusts its internal parameters to reduce the difference between its predictions and the actual outcomes. And the model keeps doing this, gradually improving its word predictions until it can reliably generate coherent sentences. Forget about bug, it can figure out it's blue. Now, the model can be fine-tuned on a smaller, more specific dataset. Here the model refines its understanding to be able to perform this specific task more accurately. Understanding is what allows a general language model to become an expert at a specific task. Okay, so how does this all fit into number three, business applications? Well, for customer service applications, businesses can use LLMs to create intelligent chatbots that can handle a variety of customer queries, freeing up human agents for more complex issues. Another good field, content creation. That can benefit from LLMs, which can help generate articles, emails, social media posts, and even YouTube video scripts. Hmm, there's an idea. Now LLMs can even contribute to software development, and they can do that by helping to generate and review code. And look, that's just scratching the surface. As large language models continue to evolve, we're bound to discover more innovative applications. And that's why I'm so enamored with large language models. If you have any questions, please drop us a line below. And if you want to see more videos like this in the future, please like and subscribe. Thanks for watching.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import itertools\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "P73TKjJGdYnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "np.random.seed(42)\n",
        "\n",
        "# Read your own text document\n",
        "with open('transcription.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "from nltk.tokenize import sent_tokenize # Import the sent_tokenize function\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Tokenize each sentence into words\n",
        "from nltk.tokenize import word_tokenize # Import the word_tokenize function\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# Define your stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Process the sentences\n",
        "processed_sentences = []\n",
        "for sentence in tokenized_sentences:\n",
        "    processed_sentences.append([word.lower() for word in sentence if word.isalnum() and word not in stop_words])\n",
        "\n",
        "# Organize the processed sentences into a dictionary (if needed)\n",
        "processed_documents = {\"transcription.txt\": processed_sentences}\n",
        "\n",
        "# Print the processed documents\n",
        "print(processed_documents)"
      ],
      "metadata": {
        "id": "8c0iyXYDdslW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0d12e9-6771-4d8d-b039-363ca9f7133b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'transcription.txt': [['welcome', 'back', 'let', 'continue', 'series', 'python', 'ws', 'cube', 'tech'], ['i', 'neha', 'video', 'going', 'talking', 'next', 'oops', 'concept', 'polyformism', 'python'], ['so', 'let', 'get', 'started'], ['so', 'let', 'break', 'word', 'polyformism'], ['so', 'like', 'polyamorphism'], ['so', 'poly', 'means', 'many', 'morphism', 'forms'], ['so', 'says', 'many', 'forms'], ['now', 'simplest', 'definition', 'polyformism', 'performing', 'task', 'different', 'way'], ['so', 'let', 'write'], ['so', 'like', 'performing', 'task', 'different', 'way'], ['so', 'performing', 'task', 'different', 'way'], ['so', 'polyformism', 'two', 'types'], ['so', 'first', 'one', 'overloading', 'overriding'], ['so', 'talk', 'overriding', 'later', 'first', 'go', 'overriding'], ['so', 'overriding', 'three', 'types', 'overriding'], ['so', 'first', 'one', 'operator'], ['the', 'second', 'one', 'method'], ['and', 'third', 'one', 'say', 'class', 'method'], ['so', 'nothing', 'say', 'overloading', 'three', 'types'], ['so', 'i', 'repeat', 'like', 'talking', 'polyformism', 'python', 'polymorphism', 'nothing', 'performing', 'task', 'different', 'way'], ['so', 'i', 'say', 'task', 'task', 'either', 'operator', 'performing', 'operator', 'different', 'way', 'method', 'performing', 'method', 'different', 'way', 'class', 'method'], ['so', 'simply', 'performing', 'class', 'method', 'different', 'way'], ['so', 'first', 'talking', 'overloading', 'concept', 'python', 'overloading', 'basically', 'three', 'types', 'going', 'see', 'one', 'one'], ['so', 'first', 'go', 'operator', 'overloading'], ['so', 'let', 'come', 'pycharm', 'file', 'going', 'write', 'code'], ['so', 'understand', 'thing', 'help', 'example'], ['so', 'say', 'example', 'i', 'variable', 'equal', '5', 'b', 'equal', 'value', 'say', 'also', '5', 'i', 'want', 'add', 'thing'], ['so', 'basically', 'i', 'like', 'i', 'taking', 'two', 'values', 'storing', 'inside', 'variable', 'i', 'simply', 'printing', 'thing'], ['now', 'see', 'plus', 'operator'], ['so', 'plus', 'operator', 'used', 'addition', 'two', 'numbers'], ['but', 'i', 'use', 'thing', 'two', 'string', 'values'], ['so', 'say', 'example', 'i', 'another', 'variable', 'i', 'wsq', 'inside', 'second', 'variable', 'i', 'tech'], ['and', 'i', 'going', 'i', 'going', 'x', 'plus', 'y'], ['and', 'see', 'i', 'run', 'course', 'see', 'giving', 'result'], ['the', 'wsq', 'tag'], ['so', 'point', 'understood', 'like', 'i', 'using', 'operator', 'plus'], ['all', 'right'], ['this', 'also', 'plus', 'plus'], ['but', 'depending', 'implementation', 'different', 'case', 'data', 'type', 'integer', 'data', 'type', 'giving', 'addition', 'result', 'whereas', 'case', 'i', 'using', 'plus', 'operator', 'string', 'data', 'type'], ['so', 'concatenating', 'strings', 'strings', 'getting', 'concatenated'], ['so', 'thing', 'i', 'said', 'performing', 'task', 'different', 'way'], ['so', 'operator', 'like', 'operator', 'implementation', 'different'], ['so', 'first', 'one', 'overload', 'operator', 'case'], ['so', 'case', 'see', 'depending', 'upon', 'type', 'data', 'implementation', 'operator', 'getting', 'changed'], ['we', 'take', 'one', 'example', 'operator', 'overloading'], ['so', 'suppose', 'case', 'i', 'going', 'take', 'asterisk', 'symbol', 'know', 'thing'], ['so', 'i', 'i', 'going', 'say', 'i', 'say', 'a1', 'equal', '5', 'i', 'say', 'b1', 'equal', 'say', '10'], ['and', 'case', 'i', 'want', 'like', 'make', 'a2', 'i', 'would', 'want', 'i', 'say', 'a1', 'a2', 'right', 'i', 'take', 'another', 'example'], ['so', 'b1', 'equal', 'say', 'i', 'string', 'suppose', 'wsq', 'tag', 'right', 'i', 'i', 'say', 'b1', '3', 'i', 'run', 'thing'], ['so', 'see', 'like', 'scenario'], ['so', 'asterisk', 'symbol', 'multiplication'], ['after', 'got', 'result', '50', 'case', 'i', 'change', 'data', 'type', 'i', 'wrote', 'string', 'i', 'said', 'b1', 'asterisk', '3'], ['so', 'case', 'repeating', 'string', 'three', 'times'], ['so', 'thing', 'operator', 'implementation', 'different'], ['so', 'another', 'example', 'operator', 'overloading', 'say'], ['so', 'first', 'one', 'overloading', 'operator', 'overloading'], ['let', 'go', 'next', 'method'], ['now', 'i', 'remove', 'code', 'talk', 'methods'], ['so', 'python', 'methods', 'worked', 'many', 'lot', 'previous', 'tutorials'], ['so', 'methods', 'python', 'compatible', 'multiple', 'data', 'types'], ['so', 'say', 'example', 'i', 'give', 'length'], ['so', 'made', 'use', 'length', 'various', 'saying', 'operator', 'sequences', 'python', 'talking', 'concept'], ['so', 'seen', 'thing', 'length'], ['so', 'try', 'implement', 'thing', 'get', 'get', 'understand', 'like', 'i', 'want', 'say'], ['so', 'basically', 'i', 'going', 'i', 'going', 'create', 'string'], ['so', 'i', 'say', 'thing', 'suppose', 'wsq', 'tag', 'minute', 'right'], ['so', 'string', 'i', 'want', 'i', 'want', 'print', 'length'], ['so', 'i', 'make', 'use', 'length', 'i', 'pass', 'x'], ['so', 'give', 'length'], ['similarly', 'i', 'use', 'length', 'method', 'data', 'types'], ['suppose', 'i', 'use', 'list', 'tuple', 'dictionary'], ['so', 'take', 'example', 'well'], ['so', 'suppose', 'i', 'creating', 'list', 'say', 'i', 'list', 'i', 'collection', 'suppose', 'i', 'name', 'brands', 'laptop'], ['so', 'say', 'example', 'i', 'hp', 'sony', 'stopped', 'still', 'write', 'understand'], ['so', 'i', 'going', 'say', 'sony', 'dell', 'right'], ['so', 'list'], ['it', 'values'], ['so', 'list', 'i', 'want', 'i', 'print', 'length'], ['so', 'i', 'say', 'length', 'i', 'say', 'pass', 'variable', 'name'], ['that', 'similarly', 'i', 'create', 'tuple', 'say', 'z', 'equal', 'know', 'declare', 'tuple', 'inside', 'round', 'bracket'], ['so', 'i', 'value', 'suppose', '1', '2', '3', '4', '5', '6', 'right', 'even', 'print', 'length'], ['so', 'i', 'say', 'print', 'length', 'i', 'pass', 'z', 'inside'], ['we', 'even', 'dictionary'], ['so', 'i', 'say', 'x', 'y', 'z', 'give', 'q', 'equal', 'write', 'curly', 'braces', 'i', 'say', 'i', 'name'], ['so', 'say', 'i', 'particular', 'key', 'value', 'suppose', 'give', 'suppose', 'i', 'x', 'y', 'z', 'give', 'one', 'key', 'value', 'pair', 'id', 'value', 'say', '1', '2', '3', 'right'], ['so', 'thing', 'i', 'even', 'print', 'thing'], ['i', 'want', 'i', 'use', 'length', 'method', 'dictionary'], ['so', 'see', 'i', 'done', 'basically', 'i', 'created', 'string', 'list', 'tuple', 'dictionary', 'i', 'i', 'making', 'use', 'built', 'method', 'length', 'i', 'run', 'thing', 'i', 'get', 'result', 'see', 'i', 'getting', 'result'], ['so', 'point', 'noticed', 'like', 'talking', 'overloading', 'right', 'talking', 'built', 'methods', 'overloading'], ['so', 'built', 'method', 'i', 'use', 'length', 'data', 'types', 'like', 'case', 'i', 'using', 'string'], ['so', 'i', 'using', 'length', 'method', 'string', 'giving', 'length', 'string', 'i', 'using', 'list', 'say', 'tuple', 'giving', 'values', 'know', 'i', 'getting', 'values', 'like', 'elements', 'present', 'inside', 'list', 'tuples', 'i', 'using', 'dictionary', 'see', 'i', 'getting', 'keys', 'keys', 'nothing', 'name', 'id'], ['so', 'based', 'upon', 'i', 'using', 'length', 'method', 'i', 'wrote', 'performing', 'task', 'different', 'way'], ['i', 'using', 'method', 'name', 'implementation', 'different'], ['this', 'i', 'wanted', 'show', 'guys'], ['so', 'built', 'method', 'overloading', 'python'], ['so', 'even', 'covered', 'thing'], ['so', 'completed', 'operator', 'overloading', 'studied', 'plus', 'asterisk', 'symbol'], ['so', 'behaves', 'differently', 'per', 'implementation', 'saw', 'built', 'method', 'length', 'method'], ['and', 'see', 'class', 'method'], ['so', 'i', 'remove', 'code'], ['so', 'class', 'method', 'i', 'say', 'class', 'method', 'basically', 'called', 'method', 'overloading', 'python'], ['so', 'basically', 'like', 'class', 'methods'], ['so', 'method', 'name', 'parameters', 'different', 'depending', 'upon', 'parameters', 'either', 'one', 'two', 'three', 'going', 'create', 'objects', 'calling', 'objects', 'parameters', 'argument', 'pass', 'depending', 'upon', 'thing', 'particular', 'method', 'called'], ['so', 'try', 'understand', 'thing', 'help', 'example'], ['so', 'suppose', 'i', 'class', 'say', 'i', 'employee', 'inside', 'basically', 'i', 'i', 'going', 'observe'], ['so', 'i', 'going', 'method', 'dev', 'i', 'say', 'greet'], ['and', 'inside', 'i', 'like', 'i', 'greet', 'i', 'another', 'argument'], ['so', 'name', 'equal', 'i', 'initialize'], ['so', 'i', 'say', 'none'], ['all', 'right'], ['and', 'basically', 'i', 'i', 'want', 'check', 'condition'], ['so', 'i', 'say', 'name', 'know', 'well', 'seen', 'operator'], ['this', 'identity', 'operator'], ['so', 'i', 'making', 'use', 'statement'], ['so', 'i', 'seeing', 'name', 'none', 'simply', 'bring', 'hello', 'person', 'name', 'suppose'], ['so', 'i', 'say', 'hello', 'plus', 'name', 'right'], ['and', 'else', 'part', 'i', 'saying', 'else', 'print', 'simply', 'hello'], ['so', 'i', 'say', 'hello', 'right'], ['so', 'i', 'basically', 'done', 'like', 'i', 'created', 'class', 'name', 'employee'], ['i', 'declared', 'one', 'function', 'greet', 'first', 'parameter', 'always', 'self', 'second', 'one', 'i', 'initialized', 'none'], ['and', 'i', 'made', 'use', 'statement', 'statement', 'i', 'using', 'identity', 'operator'], ['it', 'says', 'name', 'none', 'name', 'none', 'print', 'hello', 'name', 'fetch', 'condition', 'else', 'part', 'simply', 'says', 'print', 'hello'], ['now', 'i', 'going', 'i', 'going', 'create', 'object', 'class'], ['so', 'i', 'say', 'even', 'employee', 'order', 'call', 'function', 'i', 'make', 'use', 'object', 'name'], ['so', 'i', 'say', 'greet', 'time', 'i', 'pass', 'argument'], ['and', 'second', 'one', 'i', 'say', 'i', 'pass', 'value', 'tina'], ['so', 'code', 'work', 'fine', 'see', 'says', 'first', 'one', 'passed', 'anything', 'says', 'hello', 'second', 'scenario', 'happens', 'i', 'passed', 'argument', 'says', 'hello', 'tina'], ['so', 'basically', 'i', 'i', 'overloading', 'method', 'right', 'method', 'name', 'greet', 'change', 'except', 'implement', 'thing', 'based', 'upon', 'arguments', 'gets'], ['so', 'nothing', 'method', 'overloading', 'python'], ['so', 'i', 'repeat', 'thing'], ['so', 'basically', 'overloading', 'method', 'method', 'name', 'greet', 'one'], ['so', 'performing', 'task', 'implementation', 'different'], ['so', 'task', 'greeting', 'greeting', 'people', 'thing', 'like', 'implementation', 'different', 'name', 'none', 'none', 'go', 'case', 'hello', 'name', 'print', 'hello', 'particular', 'name', 'decide', 'depending', 'upon', 'arguments', 'passed'], ['so', 'first', 'case', 'calling', 'method', 'passing', 'argument', 'second', 'scenario', 'using', 'method', 'name', 'time', 'passing', 'argument'], ['so', 'implement', 'per', 'arguments', 'receives'], ['so', 'overloading', 'python'], ['so', 'studied', 'operator', 'overloading', 'studied', 'build', 'method', 'even', 'studied', 'class', 'method', 'overload', 'thing'], ['now', 'move', 'towards', 'overriding', 'i', 'said', 'polymorphism', 'python', 'two', 'types', 'overloading', 'overriding'], ['so', 'covered', 'overloading', 'talk', 'overriding'], ['now', 'overriding', 'two', 'types', 'variable', 'overriding'], ['and', 'even', 'method', 'overriding'], ['and', 'thing', 'like', 'overriding', 'achieved', 'help', 'inheritance'], ['so', 'i', 'talk', 'inheritance', 'going', 'classes', 'inheriting', 'one', 'another'], ['all', 'right'], ['so', 'talk', 'first', 'one', 'variable', 'overriding'], ['so', 'come'], ['and', 'basically', 'i', 'want', 'i', 'create', 'two', 'class'], ['i', 'say', 'time', 'i', 'say', 'class', 'parent', 'inside', 'parent', 'suppose', 'i', 'want', 'show', 'first', 'variable', 'overriding'], ['so', 'i', 'declare', 'variables'], ['so', 'suppose', 'i', 'say', 'def', 'i', 'make', 'use', 'int', 'inside', 'i', 'like', 'i', 'would', 'say', 'i', 'pass', 'value'], ['so', 'suppose', 'i', 'say', 'parent', 'right'], ['so', 'i', 'giving', 'value', 'seeing', 'values', 'variable'], ['all', 'right'], ['and', 'i', 'i', 'create', 'another', 'class', 'say', 'class', 'child', 'inheriting', 'properties', 'parent', 'i', 'declare', 'variables', 'i', 'say', 'i', 'giving', 'variable', 'name', 'see'], ['and', 'time', 'i', 'pass', 'value', 'child'], ['so', 'basically', 'done', 'created', 'two', 'class', 'first', 'one', 'class', 'parent', 'class', 'child', 'i', 'declared', 'variable', 'name'], ['i', 'initialized', 'pass', 'value', 'inside', 'class', 'child', 'inheriting', 'properties', 'parent'], ['so', 'parent', 'parent', 'class', 'child', 'child', 'class', 'parent', 'super', 'class', 'child', 'subclass', 'inside', 'i', 'defined', 'variable', 'name', 'i', 'given', 'value', 'child', 'variable'], ['so', 'i', 'simply', 'i', 'creating', 'object', 'child', 'class'], ['so', 'i', 'say', 'c1', 'equal', 'child', 'order', 'print', 'variable', 'name', 'name'], ['so', 'make', 'use', 'print', 'statement'], ['so', 'i', 'say', 'c1', 'dot', 'name', 'see', 'i', 'saying', 'thing', 'i', 'run', 'see', 'printing', 'child', 'fine'], ['so', 'find', 'right'], ['so', 'creating', 'object', 'child'], ['so', 'print', 'thing', 'right'], ['but', 'i', 'things'], ['suppose', 'i', 'comment', 'thing'], ['so', 'i', 'go', 'comment', 'thing'], ['and', 'know', 'know', 'use', 'pass', 'declaring', 'anything', 'inside', 'class', 'inside', 'child', 'inside', 'class', 'right'], ['we', 'simply', 'make', 'use', 'keyword', 'i', 'say', 'suppose', 'i', 'creating', 'object', 'child', 'class', 'i', 'calling', 'c1', 'dot', 'name'], ['so', 'print'], ['so', 'check'], ['you', 'see', 'printing', 'parent'], ['so', 'basically', 'happening', 'like', 'i', 'said', 'class', 'inheriting', 'properties', 'parents'], ['so', 'i', 'create', 'object', 'i', 'call', 'variable', 'name', 'help', 'object', 'name', 'c1', 'dot', 'name'], ['so', 'first', 'go', 'check', 'whether', 'getting', 'variable', 'name'], ['but', 'getting'], ['so', 'go', 'get', 'result', 'print'], ['so', 'thing', 'say', 'variable', 'getting', 'overriding', 'overriding', 'happening'], ['so', 'variable', 'overriding', 'python'], ['all', 'right'], ['so', 'see', 'thing', 'happening'], ['and', 'suppose', 'i', 'pass', 'suppose', 'right'], ['i', 'remove', 'comment', 'order', 'call', 'parent', 'variable', 'name'], ['so', 'i', 'create', 'object', 'parent', 'class'], ['i', 'say', 'p1', 'equal', 'i', 'say', 'parent'], ['and', 'i', 'thing', 'i', 'print', 'thing'], ['so', 'i', 'say', 'print', 'p1', 'dot', 'name'], ['and', 'i', 'thing', 'thing', 'print', 'parent', 'print', 'child'], ['you', 'see', 'parent', 'child'], ['all', 'right'], ['so', 'overriding', 'variable', 'overriding'], ['now', 'talk', 'method', 'overriding', 'python'], ['so', 'i', 'going', 'let', 'remove', 'thing'], ['and', 'instead', 'variable', 'i', 'declare', 'method'], ['so', 'delete', 'thing', 'i', 'say', 'def', 'say', 'method', 'name', 'hi'], ['this', 'time', 'i', 'going', 'say', 'print', 'hi', 'i', 'simply', 'say', 'hi', 'i', 'parent'], ['all', 'right'], ['so', 'method', 'inside', 'child', 'i', 'creating', 'method', 'name', 'hi'], ['and', 'time', 'i', 'print', 'i', 'say', 'print', 'hi', 'i', 'child'], ['all', 'right'], ['so', 'seeing', 'thing', 'right'], ['so', 'i', 'basically', 'done', 'like', 'i', 'created', 'class', 'parent', 'inside', 'i', 'defining', 'method', 'name', 'hi', 'printing', 'thing', 'hi', 'i', 'parent'], ['and', 'similarly', 'i', 'i', 'creating', 'another', 'class', 'child', 'inheriting', 'properties', 'parent', 'class', 'name', 'parent'], ['and', 'also', 'method', 'hi', 'printing', 'statement', 'hi', 'i', 'child'], ['and', 'i', 'want', 'i', 'want', 'create', 'object', 'class', 'child'], ['so', 'i', 'say', 'c1', 'equal', 'child'], ['and', 'inside', 'order', 'call', 'method', 'i', 'make', 'use', 'object', 'i', 'say', 'hi'], ['now', 'point', 'hi', 'method', 'execute'], ['so', 'obviously', 'execute', 'one', 'hi', 'i', 'child', 'thing'], ['all', 'right'], ['and', 'scenario', 'suppose', 'i', 'make', 'command'], ['so', 'i', 'say', 'hash', 'also'], ['and', 'i', 'say', 'pass', 'i', 'get', 'error', 'executing', 'code'], ['and', 'says', 'hi', 'i', 'parent', 'though', 'creating', 'object', 'child', 'class'], ['so', 'similar', 'thing', 'happen'], ['it', 'i', 'call', 'method', 'help', 'object', 'name', 'come', 'check', 'things', 'say', 'i', 'getting', 'anything'], ['if', 'pass', 'jump', 'parent', 'class', 'fetch', 'method', 'hi', 'print', 'thing', 'hi', 'i', 'parent'], ['and', 'similar', 'case', 'suppose', 'i', 'normal'], ['and', 'i', 'want', 'show', 'guys', 'like', 'help', 'parent', 'suppose', 'want', 'call', 'hi', 'method', 'parent', 'class', 'simply', 'need', 'create', 'object', 'parent'], ['so', 'i', 'say', 'p1', 'equal', 'i', 'say', 'parent', 'need', 'say', 'object', 'name', 'dot', 'say', 'hi'], ['and', 'thing', 'come', 'check', 'method', 'name', 'hi', 'print', 'hi', 'i', 'parent', 'thing', 'print', 'hi', 'i', 'child'], ['so', 'see', 'thing'], ['so', 'overriding', 'works'], ['this', 'method', 'overriding'], ['all', 'right'], ['so', 'quick', 'recap'], ['so', 'studied', 'polyformism', 'python'], ['so', 'said', 'polyformism', 'nothing', 'task', 'task', 'performing', 'task', 'different', 'way']]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from gensim.models import LdaModel\n",
        "from gensim import corpora\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "# Create a dictionary and corpus\n",
        "dictionary = corpora.Dictionary(list(processed_documents.values())[0])\n",
        "corpus = [dictionary.doc2bow(text) for text in list(processed_documents.values())[0]]"
      ],
      "metadata": {
        "id": "6ZoSCKZwlLbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39fffa0-22f2-4929-b099-e97a3ea4f1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "# Initialize video capture\n",
        "video_path = 'example.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    raise Exception(\"Could not open video file\")\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "if fps == 0:\n",
        "    raise Exception(\"FPS value is zero. Cannot calculate timestamp.\")\n",
        "\n",
        "def get_current_timestamp():\n",
        "    # Get the current frame number\n",
        "    current_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "    # Get the frame rate of the video\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    # Calculate the current timestamp in seconds\n",
        "    current_time_seconds = current_frame / fps\n",
        "    # Convert the timestamp to HH:MM:SS format\n",
        "    current_time_formatted = time.strftime('%H:%M:%S', time.gmtime(current_time_seconds))\n",
        "    return current_time_formatted"
      ],
      "metadata": {
        "id": "wgwvEGbR27dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import openai\n",
        "\n",
        "openai.api_key = 'sk-proj-8uShPZBYy4t9LmzTlYoRT3BlbkFJXY2mTZcNB7gkVlgFe1B6'\n",
        "\n",
        "# Function to generate applications or facts for each topic\n",
        "def generate_applications_or_facts(topic):\n",
        "    prompt = f\"Provide general life applications or facts based on the following topic: {topic}\"\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n"
      ],
      "metadata": {
        "id": "NYz-vAhCGRqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of topics we want to extract\n",
        "num_topics = 3\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
        "\n",
        "# Extract the topics with their word distributions\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "\n",
        "# Refine topics into short sentences\n",
        "refined_topics = []\n",
        "for idx, topic in topics:\n",
        "    words = [word.split('*')[1].strip().strip('\"') for word in topic.split('+')]\n",
        "    refined_sentence = \" \".join(words)\n",
        "\n",
        "    # # Process video to next timestamp point\n",
        "    # # Assuming a fixed amount of time (e.g., 10 seconds) per topic for simplicity\n",
        "    # end_timestamp = None\n",
        "    # for _ in range(300):  # 300 frames at 30 FPS approximates 10 seconds\n",
        "    #     ret, frame = cap.read()\n",
        "    #     if not ret:\n",
        "    #         break\n",
        "    #     timestamp = get_current_timestamp()\n",
        "\n",
        "    # end_timestamp = get_current_timestamp()  # Get the current timestamp when this topic ends\n",
        "    refined_topics.append(f\"Topic #{idx + 1}: {refined_sentence}\")\n",
        "    # refined_topics_.append(f\"Topic #{idx + 1}: {refined_sentence} (ends at {end_timestamp})\")\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# Print the topics with their word distributions\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Topic #{idx + 1}: {topic}\")\n",
        "\n",
        "\n",
        "# Print the refined topics\n",
        "for refined_topic in refined_topics_with_timestamps:\n",
        "    print(refined_topic)"
      ],
      "metadata": {
        "id": "RdbRXld8k_I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adce5dda-6b27-47d0-f9cd-fe7e2383e021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1: 0.083*\"i\" + 0.041*\"method\" + 0.035*\"so\" + 0.017*\"one\" + 0.016*\"using\" + 0.015*\"thing\" + 0.015*\"string\" + 0.014*\"overloading\" + 0.013*\"and\" + 0.012*\"basically\"\n",
            "Topic #2: 0.091*\"so\" + 0.057*\"i\" + 0.026*\"see\" + 0.021*\"overriding\" + 0.020*\"operator\" + 0.019*\"thing\" + 0.016*\"all_right\" + 0.016*\"suppose\" + 0.015*\"different_way\" + 0.013*\"performing_task\"\n",
            "Topic #3: 0.144*\"i\" + 0.076*\"so\" + 0.062*\"say\" + 0.026*\"class\" + 0.025*\"method\" + 0.024*\"thing\" + 0.024*\"parent\" + 0.022*\"and\" + 0.021*\"child\" + 0.018*\"name\"\n",
            "Topic #1: so method overriding right thing (ends at 00:00:12)\n",
            "Topic #2: i so say operator class (ends at 00:00:25)\n",
            "Topic #3: i so name say print (ends at 00:00:37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refining it even more"
      ],
      "metadata": {
        "id": "L_QaaNq3oyaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "# Initialize video capture\n",
        "video_path = 'example.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    raise Exception(\"Could not open video file\")\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "if fps == 0:\n",
        "    raise Exception(\"FPS value is zero. Cannot calculate timestamp.\")"
      ],
      "metadata": {
        "id": "vixPg6nRBw3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare CSV file\n",
        "csv_file = 'topics_timestamps.csv'\n",
        "csv_columns = ['timestamp', 'topic', 'fact']\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Read your own text document\n",
        "with open('transcription.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Tokenize each sentence into words\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# Define your stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Process the sentences\n",
        "processed_sentences = []\n",
        "for sentence in tokenized_sentences:\n",
        "    processed_sentences.append([word.lower() for word in sentence if word.isalnum() and word not in stop_words])\n",
        "\n",
        "# Identify common bigrams and trigrams\n",
        "phrases = Phrases(processed_sentences, min_count=2, threshold=5)\n",
        "bigram = Phraser(phrases)\n",
        "trigram = Phraser(Phrases(bigram[processed_sentences], threshold=5))\n",
        "\n",
        "# Transform sentences to include bigrams and trigrams\n",
        "processed_sentences = [trigram[bigram[sentence]] for sentence in processed_sentences]\n",
        "\n",
        "# Create a dictionary representation of the documents\n",
        "dictionary = corpora.Dictionary(processed_sentences)\n",
        "\n",
        "# Create a corpus from the dictionary representation\n",
        "corpus = [dictionary.doc2bow(sentence) for sentence in processed_sentences]\n",
        "\n",
        "# Set the number of topics you want to extract\n",
        "num_topics = 5\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
        "\n",
        "# Extract the topics with their word distributions\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "\n",
        "# Refine topics into meaningful phrases\n",
        "def refine_topic(topic):\n",
        "    words = [word.split('*')[1].strip().strip('\"') for word in topic.split('+')]\n",
        "    meaningful_phrases = []\n",
        "    used_words = set()\n",
        "    for word in words:\n",
        "        if word in used_words:\n",
        "            continue\n",
        "        for phrase in processed_sentences:\n",
        "            if word in phrase:\n",
        "                meaningful_phrases.append(' '.join(phrase))\n",
        "                used_words.update(phrase)\n",
        "                break\n",
        "    return meaningful_phrases\n",
        "\n",
        "refined_topics = []\n",
        "with open(csv_file, 'w', newline='') as csvfile:\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
        "  writer.writeheader()\n",
        "  for idx, topic in topics:\n",
        "      phrases = refine_topic(topic)\n",
        "      applications_or_facts = generate_applications_or_facts(topic)\n",
        "      end_timestamp = None\n",
        "      for _ in range(300):  # 300 frames at 30 FPS approximates 10 seconds\n",
        "          ret, frame = cap.read()\n",
        "          if not ret:\n",
        "              break\n",
        "          timestamp = get_current_timestamp()\n",
        "\n",
        "      end_timestamp = get_current_timestamp()  # Get the current timestamp when this topic ends\n",
        "      refined_topic_with_timestamp = {\n",
        "              'timestamp': end_timestamp,\n",
        "              'topic': f\"Topic #{idx + 1}\",\n",
        "              'fact': applications_or_facts\n",
        "      }\n",
        "      writer.writerow(refined_topic_with_timestamp)\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Print the refined topics\n",
        "for refined_topic in refined_topics:\n",
        "    print(refined_topic)\n",
        "\n",
        "print(f\"Topics, timestamps, and facts have been saved to {csv_file}\")"
      ],
      "metadata": {
        "id": "8dxXVtjieGrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e914b510-faef-4191-ebb1-7f05de0950bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics, timestamps, and facts have been saved to topics_timestamps.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Generate applications or facts for each topic\n",
        "for topic in refined_topics:\n",
        "    applications_or_facts = generate_applications_or_facts(topic)\n",
        "    print(f\"Applications or facts for {topic}:\\n{applications_or_facts}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6KVDJOveo8uQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43884655-86ae-4b9a-861b-e146da03db29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applications or facts for Topic #1: so first_one overloading overriding; the second_one method; i neha video going talking next oops concept polyformism_python; now simplest definition polyformism performing_task different_way; and third one say class method(ends at 00:01:15)):\n",
            "1. Overloading and overriding are two important concepts in programming, particularly in object-oriented languages like Java or C++. \n",
            "2. Overloading allows a developer to create multiple methods with the same name but with different parameters or argument types, allowing for more flexibility in coding.\n",
            "3. On the other hand, overriding refers to the process of replacing an existing method in a superclass with a new implementation in a subclass.\n",
            "4. Both overloading and overriding help to make code more concise and organized, making it easier to maintain and update in the future.\n",
            "5. In the context of OOP, polymorphism is the ability of an object to take on different forms and behave differently based on the context in which it is used.\n",
            "6. In Python,\n",
            "\n",
            "Applications or facts for Topic #2: i neha video going talking next oops concept polyformism_python; and third one say class method; i say time i say class parent inside parent suppose i want show first variable_overriding; and time i pass_value child(ends at 00:01:27)):\n",
            "1. The concept of polymorphism in Python can be applied to real-life situations such as different people playing different roles in a team project or a parent object having multiple child objects.\n",
            "\n",
            "2. Understanding inheritance, which is a part of object-oriented programming, can help in creating organized and efficient family trees or organizational hierarchies.\n",
            "\n",
            "3. The use of class methods can be seen in everyday scenarios such as a baker using the same method to make different types of pastries or a teacher using a teaching method for various subjects.\n",
            "\n",
            "4. Overriding a variable can be likened to a child inheriting a physical trait from one parent over the other, showing the dominant aspect of the gene.\n",
            "\n",
            "5. Passing values between objects in coding can be compared to\n",
            "\n",
            "Applications or facts for Topic #3: i neha video going talking next oops concept polyformism_python; so let get started; and third one say class method; so suppose i creating list say i list i collection suppose i name brands laptop(ends at 00:01:40)):\n",
            "1. Understanding polymorphism in programming languages can help you navigate and troubleshoot software applications more effectively.\n",
            "\n",
            "2. The concept of polymorphism can also be applied in other fields, such as biology, where it refers to the ability of a single gene to have multiple phenotypic effects.\n",
            "\n",
            "3. Knowing how to use polymorphism in programming can make your code more efficient and adaptable, just like how different objects can exhibit different behaviors depending on their class.\n",
            "\n",
            "4. When creating a list or collection, being aware of polymorphism can help you efficiently store different types of data, such as strings and integers, in a single structure.\n",
            "\n",
            "5. Brands of laptops can be considered as different \"types\" of the overall category of laptops, showcasing how polymorphism\n",
            "\n",
            "Applications or facts for Topic #4: i neha video going talking next oops concept polyformism_python; and third one say class method; so let get started; so delete thing i say def say method name hi(ends at 00:01:52)):\n",
            "1. The concept of polymorphism in programming allows for more efficient and flexible coding, similar to how humans can adapt and perform different tasks using the same set of abilities.\n",
            "2. Just like how one person can have different roles in different situations, a class method in programming can have different functions depending on the class it is called from.\n",
            "3. In real life, we also use polymorphism in language by using the same word to mean different things in different contexts (e.g. \"crane\" as a bird or a heavy machinery).\n",
            "4. The ability to delete things, whether it be code or physical objects, is crucial in minimizing clutter and improving overall efficiency.\n",
            "5. The \"hi\" method in programming is similar to how we greet\n",
            "\n",
            "Applications or facts for Topic #5: so let get started; i neha video going talking next oops concept polyformism_python; so understand thing help example; so like polyamorphism; so first_one overloading overriding(ends at 00:02:05)):\n",
            "1. \"So let's get started\" is a commonly used phrase to begin a task or activity, indicating excitement and readiness to begin.\n",
            "\n",
            "2. The name \"Neha\" is of Indian origin and means \"love\" or \"longing.\"\n",
            "\n",
            "3. Videos are a popular form of media used for entertainment, learning, and communication in today's digital age.\n",
            "\n",
            "4. Communication and understanding can be enhanced through the use of visual aids, such as videos.\n",
            "\n",
            "5. The concept of polyformism in Python refers to the ability of an object or method to take on multiple forms or behaviors, depending on the context in which it is used.\n",
            "\n",
            "6. Understanding the concept of polyformism in coding can help developers write more efficient and versatile\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim nltk pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_no4M4ZtaP2",
        "outputId": "b2f24fe3-112c-4add-e866-167294df3426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "import numpy as np\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Define the transcript\n",
        "def read_transcript(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        transcript = file.read()\n",
        "    return transcript\n",
        "\n",
        "# Path to transcript file\n",
        "transcript_file = '/content/transcription.txt'\n",
        "\n",
        "# Read transcript from file\n",
        "transcript = read_transcript(transcript_file)\n",
        "\n",
        "# Preprocess the transcript\n",
        "def preprocess(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    filtered_tokens = [\n",
        "        lemmatizer.lemmatize(word) for word in tokens\n",
        "        if word.isalnum() and word not in stop_words\n",
        "    ]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Tokenize and preprocess the transcript\n",
        "tokens = preprocess(transcript)\n",
        "tokens_joined = ' '.join(tokens)\n",
        "\n",
        "# Calculate TF-IDF scores\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform([tokens_joined])\n",
        "tfidf_scores = np.array(tfidf_matrix.mean(axis=0)).flatten()\n",
        "tfidf_vocab = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Filter out words with low TF-IDF scores\n",
        "threshold = 0.15  # Adjust the threshold as needed\n",
        "significant_words = [word for word, score in zip(tfidf_vocab, tfidf_scores) if score > threshold]\n",
        "\n",
        "# Create a dictionary and a corpus using significant words only\n",
        "dictionary = corpora.Dictionary([significant_words])\n",
        "corpus = [dictionary.doc2bow(significant_words)]\n",
        "\n",
        "# Set the number of topics\n",
        "num_topics = 3\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LdaModel(\n",
        "    corpus,\n",
        "    num_topics=num_topics,\n",
        "    id2word=dictionary,\n",
        "    passes=15,\n",
        "    alpha='auto',\n",
        "    eta='auto'\n",
        ")\n",
        "\n",
        "# Print the topics\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Topic: {idx}\\nWords: {topic}\\n\")\n",
        "\n",
        "# Get the dominant topic for the document\n",
        "def get_dominant_topic(lda_model, corpus):\n",
        "    for doc in corpus:\n",
        "        topic_probs = lda_model.get_document_topics(doc)\n",
        "        dominant_topic = sorted(topic_probs, key=lambda x: x[1], reverse=True)[0]\n",
        "        topic_id = dominant_topic[0]\n",
        "        topic_terms = lda_model.show_topic(topic_id)\n",
        "        topic_words = \", \".join([term for term, weight in topic_terms])\n",
        "        return topic_words\n",
        "\n",
        "dominant_topic_words = get_dominant_topic(lda_model, corpus)\n",
        "print(f\"Dominant Topic Words: {dominant_topic_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3SfR-vExDUD",
        "outputId": "7307466d-260a-4469-9e2a-2fb9835fd925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0\n",
            "Words: 0.143*\"data\" + 0.143*\"large\" + 0.143*\"model\" + 0.143*\"llm\" + 0.143*\"language\" + 0.143*\"text\" + 0.143*\"word\"\n",
            "\n",
            "Topic: 1\n",
            "Words: 0.143*\"text\" + 0.143*\"word\" + 0.143*\"language\" + 0.143*\"data\" + 0.143*\"model\" + 0.143*\"large\" + 0.143*\"llm\"\n",
            "\n",
            "Topic: 2\n",
            "Words: 0.143*\"word\" + 0.143*\"llm\" + 0.143*\"language\" + 0.143*\"large\" + 0.143*\"model\" + 0.143*\"text\" + 0.143*\"data\"\n",
            "\n",
            "Dominant Topic Words: data, large, model, llm, language, text, word\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = 'sk-proj-8uShPZBYy4t9LmzTlYoRT3BlbkFJXY2mTZcNB7gkVlgFe1B6'\n",
        "\n",
        "dominant_topic_words_list = [word.strip() for word in dominant_topic_words.split(\",\")]\n",
        "\n",
        "# Function to generate a fact using OpenAI API\n",
        "def generate_fact(topic):\n",
        "    prompt = f\"Generate an interesting fact about {topic}.\"\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    fact = response.choices[0].text.strip()\n",
        "    return fact\n",
        "\n",
        "# Generate and print a fact for each dominant topic word\n",
        "for topic in dominant_topic_words_list:\n",
        "    fact = generate_fact(topic)\n",
        "    print(f\"Did you know? {fact}\")"
      ],
      "metadata": {
        "id": "eqPbRXxyq0tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f60198-26a9-4bab-d3b2-08bf96886142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did you know? Data is estimated to double every two years, meaning that the amount of data in the world today is equivalent to the amount of data that existed in the entire history of humanity up until two years ago.\n",
            "Did you know? The largest living organism on Earth is a fungus called Armillaria ostoyae, also known as the \"humongous fungus.\" It covers 2,200 acres (8.9 square kilometers) in Oregon's Blue Mountains and is estimated to be around 2,400 years old.\n",
            "Did you know? One interesting fact about models is that they can be used to simulate and predict real world scenarios, such as weather patterns, economic trends, and disease outbreaks. This allows scientists and researchers to better understand and prepare for potential future events.\n",
            "Did you know? LLM stands for \"Legum Magister\" which translates to \"Master of Laws\" in Latin. It is a postgraduate degree in law that is typically pursued by those who have already completed a Juris Doctor (JD) degree.\n",
            "Did you know? There are over 7,000 languages spoken in the world today, but half of the world's population speaks just 23 of them.\n",
            "Did you know? Text is the most commonly used form of communication in the world, with over 5 billion people sending and receiving text messages every day.\n",
            "Did you know? The word \"queue\" is the only word in the English language that is pronounced the same way when the last four letters are removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Function to preprocess and tokenize text\n",
        "def preprocess_text(text):\n",
        "    # Tokenize text\n",
        "    doc = nlp(text)\n",
        "    # Remove stopwords, punctuation, and numbers\n",
        "    tokens = [token.text.lower() for token in doc if token.text.lower() not in STOP_WORDS and token.text.isalpha() and token.text.lower() not in string.punctuation]\n",
        "    return tokens\n",
        "\n",
        "# Function to extract noun phrases\n",
        "def extract_noun_phrases(text):\n",
        "    doc = nlp(text)\n",
        "    noun_phrases = []\n",
        "    for chunk in doc.noun_chunks:\n",
        "        noun_phrase = chunk.text\n",
        "        noun_phrases.append(noun_phrase)\n",
        "    return noun_phrases\n",
        "\n",
        "# Read transcript from file\n",
        "def read_transcript(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        transcript = file.read()\n",
        "    return transcript\n",
        "\n",
        "# Path to transcript file\n",
        "transcript_file = '/content/transcription.txt'\n",
        "\n",
        "# Read transcript from file\n",
        "transcript = read_transcript(transcript_file)\n",
        "\n",
        "# Preprocess and tokenize transcript\n",
        "tokens = preprocess_text(transcript)\n",
        "processed_text = ' '.join(tokens)\n",
        "\n",
        "# Extract noun phrases\n",
        "noun_phrases = extract_noun_phrases(processed_text)\n",
        "\n",
        "# Count frequency of each noun phrase\n",
        "phrase_counts = Counter(noun_phrases)\n",
        "\n",
        "# Print dominant phrases (top 5 most frequent)\n",
        "print(\"Dominant Phrases:\")\n",
        "for phrase, count in phrase_counts.most_common(5):\n",
        "    print(f\"{phrase}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPvgeDZhum8r",
        "outputId": "744f7916-8fd0-4368-8038-8ce34c656f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dominant Phrases:\n",
            "things: 3\n",
            "llms: 2\n",
            "model: 2\n",
            "large language models: 2\n",
            "enormous amounts text data: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2o7qL741Q80"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}